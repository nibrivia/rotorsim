---
title: "3nets"
author: "Olivia Brode-Roger"
date: "1/18/2020"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(tidyverse)
library(hrbrthemes)
library(scales)
```

```{r data, }
end_times <- read_csv("../simulator/out.csv")
flows     <- read_csv("../simulator/flows.csv") %>%
    left_join(end_times, by = c("id" = "flow_id")) %>% 
    mutate(fct = time_ms - arrival)

flows %>%
    filter(!is.na(fct)) %>% 
    ggplot(aes(x = size_bytes/1e6,
               y = fct)) +
    geom_point() +
    geom_abline(slope = 1, intercept = -1) + # because log scale...
    scale_x_log10(breaks = c(.01, .1, 1, 10, 100, 1000, 10e3),
                  labels = c("10Kb", "100Kb", "1Mb", "10Mb", "100Mb", "1Gb", "10Gb")) +
    scale_y_log10(breaks = c(.001, .01, .1, 1, 10, 100, 1000),
                  labels = c("1us", "10us", "100us", "1ms", "10ms", "100ms", "1s")) +
    theme_ipsum_rc() +
    labs(title = "Flow completion times",
         x = "Flow size",
         y = "Flow completion time",
         caption = "github.com/nibrivia/rotorsim")
```

```{r cdf, }
fct_cdf <- flows %>% 
    filter(!is.na(fct)) %>% 
    arrange(fct) %>% 
    mutate(completed = seq_along(fct)/length(fct))

fct_cdf %>%
    rbind(fct_cdf_no_cache %>% mutate(type = "no cache")) %>% 
    ggplot(aes(x = fct,
               y = completed,
               color = type)) +
    #geom_line() +
    geom_point(size = .2) +
    scale_y_continuous(labels = percent) +
    scale_x_log10(breaks = c(.001, .01, .1, 1, 10, 100, 1000),
                  labels = c("1us", "10us", "100us", "1ms", "10ms", "100ms", "1s")
                  ) +
    theme_ipsum_rc() +
    annotate("point", y = 1, x=max(fct_cdf$fct), size = 2) +
    labs(title = "CDF of flow completion times",
         y = NULL,
         x = "Flow completion time",
         caption = "github.com/nibrivia/rotorsim")
```

```{r many-experiments, }
dir <- "../simulator/"
flow_fns <- list.files(path = dir, pattern = "drain.*1000ms.csv")
experiments <- tibble(filename = flow_fns) %>%
    mutate(exp_id     = seq_along(filename),
           base_fn    = strsplit(flow_fns, "ms.csv") %>% map_chr(1) %>% strsplit("drain-") %>% map_chr(2),
           split = strsplit(base_fn, "-"),
           n_tor      = as.integer(map_chr(split, 1)),
           n_switches = strsplit(map_chr(split, 2), ":"),
           n_cache    = as.integer(map_chr(n_switches, 2)),
           n_switches = as.integer(map_chr(n_switches, 1)),
           load       = as.double(map_chr(split, 3)),
           duration   = as.integer(map_chr(split, 4))) %>% 
    filter(n_cache %in% c(0, 16)) %>% 
    #filter(load %in% c(.1, .4, .8)) %>% 
    select(-split, -base_fn)

if (FALSE) {
  arrivals <- experiments %>% 
      mutate(arrivals = map(paste0(dir, base_fn, ".csv"), read_csv)) %>% 
      select(exp_id, arrivals) %>% 
      unnest(arrivals) %>% 
      rename(end = time_ms)
  
  flows <- experiments %>% 
      mutate(flows = map(paste0(dir, filename), col_types = "ddd--", read_csv)) %>% 
      select(exp_id, flows) %>% 
      unnest(flows) %>% 
      rename(flow_id = id,
             start   = arrival) %>% 
      left_join(arrivals, by = c("flow_id", "exp_id"))
  
  fcts <- flows %>% 
      filter(!is.na(end),
             exp_id %in% c(1, 2,  3,  4,  5 , 6,  7, 35, 36, 37, 38, 39, 40, 41)) %>% 
      mutate(fct = end-start) %>% 
      group_by(exp_id, size_bytes) %>% 
          arrange(fct) %>% 
          mutate(cdf = seq_along(fct)/length(fct)) %>% 
          ungroup() %>% 
      left_join(experiments %>% select(n_cache, load, exp_id), by = c("exp_id"))
}

flows <- experiments %>% 
  mutate(arrivals = map(paste0(dir, filename), read_csv, col_types = "iciidddd")) %>% 
  select(exp_id, arrivals) %>% 
  unnest(arrivals) %>% 
  mutate(size_gb = size/1e9)


arrive_at_start <- TRUE
if (arrive_at_start) {
  end_times <- flows %>%
    #filter(flow_id > 16512) %>%
    
    group_by(exp_id, src, dst) %>% 
      summarize(end = max(end),
                size_gb = sum(size_gb)) %>% 
    group_by(exp_id) %>%
      summarize(gbits_sent = sum(size_gb),
                mean = weighted.mean(end, wt = size_gb),
                `90%-ile` = quantile(end, .9),
                `99%-ile` = quantile(end, .99),
                max  = max(end)
                ) %>%
      ungroup() %>% 
    reshape2::melt(measure.vars = c("mean", "90%-ile", "99%-ile", "max"),
                   variable.name = "type",
                   value.name    = "fct") %>% 
    left_join(experiments) %>%
    mutate(real_load = gbits_sent/(n_tor*n_switches*10*duration/1000))
    
  stat_type <- "99%-ile"
  end_times %>% 
    filter(type == stat_type) %>% 
    ggplot(aes(x = real_load,
               y = fct/1000,
               color = as_factor(n_cache),
               shape = as_factor(n_cache))) +
    #geom_smooth(method = "lm",
    #            size = .2) +
    geom_abline(slope = end_times$duration[1]/1000) +
    geom_line() +
    #geom_label(aes(label = load), nudge_x = .02) +
    annotate("blank", x = c(0.8), y = c(2.5)) +
    geom_point(size = 4) +
    scale_x_percent() +
    theme_ipsum_rc() +
    theme(legend.position = c(.1, .8),
          legend.background = element_rect(fill = alpha("white", .7),
                                           size = 0)) +
    labs(title = paste(stat_type, "drainage time per rotor-pair"),
         subtitle = "129 ToRs for 1s, 32 switches, 0 expander",
         color = "# cache sw",
         shape = "# cache sw",
         linetype = NULL,
         x = "Actual load",
         y = "Demand completion time",
         caption = "https://github.com/nibrivia/rotorsim")
}
```

```{r}
fcts <- flows %>% 
  mutate(fct = end - start) %>% 
  group_by(exp_id, size) %>% 
    arrange(fct, .by_group = TRUE) %>% 
    mutate(cdf = seq_along(fct)/length(fct)) %>% 
    ungroup()
    
  


fcts %>%
  sample_n(10000000) %>%
  left_join(experiments, by = "exp_id") %>% 
  ggplot(aes(x = size/1e6,
             y = fct,
             group = paste(exp_id, size),
             color = as_factor(n_cache))) +
  geom_violin(draw_quantiles = c(.1, .5, .9), scale = "width") +
  geom_abline(slope = 1, intercept = -1) + # because log scale...
  scale_x_log10(breaks = c(.01, .1, 1, 10, 100, 1000, 10e3),
                labels = c("10Kb", "100Kb", "1Mb", "10Mb", "100Mb", "1Gb", "10Gb")) +
  scale_y_log10(breaks = c(.001, .01, .1, 1, 10, 100, 1000),
                labels = c("1us", "10us", "100us", "1ms", "10ms", "100ms", "1s")) +
  theme_ipsum_rc() +
  facet_wrap(~load) +
  labs(title = "Flow completion times",
       subtitle = "257 ToRs, 2000ms. 33 switches: 1 expander, and {0, 16} cache switches",
       x = "Flow size",
       y = "Flow completion time",
       caption = "github.com/nibrivia/rotorsim")


fcts %>% 
  filter(size > 1e6) %>% 
    #sample_n(1000000) %>% 
    left_join(experiments, by = "exp_id") %>% 
    mutate(load = paste0(as.numeric(load)*100, "%")) %>% 
    ggplot(aes(x = fct,
               y = cdf,
               color = as.factor(n_cache),
               group = exp_id)) +
    geom_line() +
    #geom_point(size = .2) +
    scale_y_continuous(labels = percent) +
    scale_x_log10(#breaks = c(.001, .01, .1, 1, 10, 100, 1000),
                  #labels = c("1us", "10us", "100us", "1ms", "10ms", "100ms", "1s")
                  ) +
    theme_ipsum_rc() +
    facet_grid(size~load, scales = "free_x") +
    labs(title = "CDF of flow completion times by load and flow size",
         subtitle = "129 ToRs, 1000ms. 33 switches: 1 expander, and {0, 16} cache switches",
         color = "# cache switches",
         y = NULL,
         x = "Flow completion time",
         caption = "github.com/nibrivia/rotorsim")

    
```
